2017-08-08 00:00:14,328 : Removing: 2017-08-07-samtools_count_para_reg_multiprocess_py.md
2017-08-08 00:00:14,329 : Entering Front Matter class
2017-08-08 00:00:14,329 : Front matter field: date value 2017-08-08
2017-08-08 00:00:14,329 : Front matter field: title value Parallel by Region (py)
2017-08-08 00:00:14,329 : Front matter field: categories value parallel
2017-08-08 00:00:14,329 : Front matter field: categories value python
2017-08-08 00:00:14,330 : Front matter field: github_link value https://github.com/Damien-Black/dnanexus-example-applets/tree/master/Tutorials/python/samtools_count_para_reg_multiprocess_py
2017-08-08 00:00:14,331 : front matter written
2017-08-08 00:00:14,331 : Code region search
2017-08-08 00:00:14,332 : regular comment, line: #!/usr/bin/env python
2017-08-08 00:00:14,332 : regular comment, line: #
2017-08-08 00:00:14,332 : regular comment, line: # This app performs a SAMtools count via the following implementation:
2017-08-08 00:00:14,332 : regular comment, line: #   - dxpy.download_all_inputs is used.
2017-08-08 00:00:14,332 : regular comment, line: # SAMtools count in parallel per region (multi core) using multiprocess
2017-08-08 00:00:14,332 : block comment, line: """
2017-08-08 00:00:14,333 : block comment, line: """
2017-08-08 00:00:14,333 : block comment, line: """
2017-08-08 00:00:14,333 : block comment, line: """
2017-08-08 00:00:14,333 : block comment, line: """
2017-08-08 00:00:14,333 : block comment, line: """
2017-08-08 00:00:14,334 : regular comment, line: # Not required.  Making sure all files generated will be
2017-08-08 00:00:14,334 : regular comment, line: # in an easy to find location if ssh is needed.
2017-08-08 00:00:14,334 : regular comment, line: # dxpy.download_all_inputs will download all input files into
2017-08-08 00:00:14,334 : regular comment, line: # the /home/dnanexus/in directory.  A folder will be created for each
2017-08-08 00:00:14,335 : regular comment, line: # input and the file(s) will be download to that directory.
2017-08-08 00:00:14,335 : regular comment, line: #
2017-08-08 00:00:14,335 : regular comment, line: # In this example out dictionary inputs has the following key, value pairs
2017-08-08 00:00:14,335 : regular comment, line: #     mappings_sorted_bam_path: [u'/home/dnanexus/in/mappings_sorted_bam/SRR504516.bam']
2017-08-08 00:00:14,335 : regular comment, line: #     mappings_sorted_bam_name: u'SRR504516.bam'
2017-08-08 00:00:14,335 : regular comment, line: #     mappings_sorted_bam_prefix: u'SRR504516'
2017-08-08 00:00:14,336 : regular comment, line: #     mappings_sorted_bai_path: u'/home/dnanexus/in/mappings_sorted_bai/SRR504516.bam.bai'
2017-08-08 00:00:14,336 : regular comment, line: #     mappings_sorted_bai_name: u'SRR504516.bam.bai'
2017-08-08 00:00:14,336 : regular comment, line: #     mappings_sorted_bai_prefix: u'SRR504516'
2017-08-08 00:00:14,336 : regular comment, line: # SAMtools view command required the bam.bai index file to be in the same
2017-08-08 00:00:14,336 : regular comment, line: # directory as the bam when specifying regions.
2017-08-08 00:00:14,336 : regular comment, line: #
2017-08-08 00:00:14,337 : regular comment, line: # When accessing key, value pairs from inputs dictionary note that the
2017-08-08 00:00:14,337 : regular comment, line: # values are stored as a list.
2017-08-08 00:00:14,337 : regular comment, line: # If our inputs were specified as array:files
2017-08-08 00:00:14,337 : regular comment, line: # our list would contain more than 1 element
2017-08-08 00:00:14,337 : regular comment, line: # Create list of regions to parallelize
2017-08-08 00:00:14,337 : regular comment, line: # In parallel create workers for each region and generate view cmds
2017-08-08 00:00:14,338 : regular comment, line: # Run in parallel using multiprocessing.  multiprocessing.pool class takes
2017-08-08 00:00:14,338 : regular comment, line: # an optional argument 'processes' for how many cores the created workers
2017-08-08 00:00:14,338 : regular comment, line: # can work on.  When not specified 'processes' = # of cores on system
2017-08-08 00:00:14,338 : regular comment, line: # Assigning processes=cpu_count() explicitly is not needed.
2017-08-08 00:00:14,338 : regular comment, line: #
2017-08-08 00:00:14,339 : regular comment, line: # We process first then verify the results of processing. Throwing an
2017-08-08 00:00:14,339 : regular comment, line: # AppInternalError if any commands failed. Review the verify_pool_status()
2017-08-08 00:00:14,339 : regular comment, line: # function for details as to how job error logging works.
2017-08-08 00:00:14,339 : regular comment, line: # Write results to file
2017-08-08 00:00:14,339 : regular comment, line: # Create dictionary to be returned as output for the job
2017-08-08 00:00:14,339 : regular comment, line: # Dictionary must contain keys matching outputs set in dxapp.json
2017-08-08 00:00:14,340 : Creating code regions
2017-08-08 00:00:14,340 : Force line match: We create several helpers in our applet script to split run process our workload. One helper you may have seen before is `run_cmd`, we use this function to manage or subprocess calls:
2017-08-08 00:00:14,340 : Adding Func: run_cmd
2017-08-08 00:00:14,590 : Force line match: Before we can split our workload, we need to know what regions are present in our BAM input file. We handle this initial parsing in the `parse_sam_header_for_region` function:
2017-08-08 00:00:14,591 : Adding Func: parse_sam_header_for_region
2017-08-08 00:00:14,596 : Force line match: {% include note.html content="The `run_cmd` function return a tuple containing the stdout, stderr, and exit code of the subprocess call. We parse these outputs from our workers to determine a failed or a passed run." %}
2017-08-08 00:00:14,596 : Adding Func: verify_pool_status
